# 一致性哈希

我们已经实现了单机的 HTTP 服务，接下来我们要实现分布式缓存，那么一旦转移到分布式环境下，各个节点之间的一致性问题就出现了，而一致性哈希算法就是 GeeCache 从单节点走向分布式节点的一个重要环节。

> 夺命三连：一致性哈希算法是啥？为什么要用一致性哈希算法？和分布式有什么关系？

# 访问哪一个节点？

思考一个问题：对于分布式缓存来说，如果一个节点接收到查询请求，但是这个节点并没有缓存该 key 的值，这时它应该从哪个节点那里获得缓存数据呢？或者说它如何知道哪一个节点可能有这个 key 的缓存值呢？

我们不妨假设一个分布式缓存系统中有 10 个节点，如果我们的查询策略是：

当一个节点收到查询请求后，随机从 10 个节点中挑选出一个作为数据源，然后将查询请求转发给这个节点，假设为节点 1，节点收到查询请求后，从慢速数据库中查询该 key 的值并缓存起来，然后返回给请求方。

第二次，同样的 key 查询请求到达，这次选择到已经缓存了 key 值的节点 1 的概率只是 9/10，如果选择了其他节点，那么其他节点也需要从慢速数据库中再查一遍然后缓存起来，一般来说，从数据库中查询数据因为涉及到磁盘 IO，因此是很耗时的。那么采用这种查询策略有两个问题：一是缓存效率低，二是各个节点上缓存了大量相同的数据，存在高缓存冗余，浪费了内存空间。

从上面的例子不难想到，只要我们可以将某个 key 每次都能选择一个固定的节点，那么这个问题就解决了。

> hash 算法具有单向性、碰撞抵抗性（不同 key 产生相同 hash 值的概率非常低）、均匀性（输入均匀的映射到哈希值的范围内）、快速计算（在合理时间内计算出 hash 值、64 轮）；因为 hash 算法是确定性的，给定相同的输入，哈希算法总是产生相同的输出，这是 hash 算法的基本特性，保证了数据的一致性和可验证性。hash 算法通过将输入映射到一个固定大小的哈希值空间，这个映射过程是确定性的（每个 hash 算法使用的随机 hash 种子不同，确定了 hash 种子，进行 64 轮循环，最终得到一个确定的值，这个值反过来推导出原值，也就是哈希原像）。

# 节点数量动态变化

我们可以使用 hash 算法将相同的 key 的请求发送给固定的节点，避免了节点缓存大量重复数据的空间占用问题和随机选择节点查询造成的性能问题。

但是我们还没有考虑节点数量动态变化的问题，因为一旦节点数量发生了变化，那么我们根据 hash 值取余得到的节点也发生了改变，这意味着可能所有的 key 通过 hash 运算对节点数量取余后得到的节点和之前选择的节点都不同了，这意味着整个分布式缓存中的缓存值都失效了。

节点在接收到对应请求后，均需要重新去数据源获取数据，这非常容易导致缓存雪崩。

> 为什么会导致缓存雪崩呢？按照刚才的假设，一旦某个节点加入或者退出，那么缓存相当于失效（等同于缓存服务器宕机或者缓存设置相同的过期时间同时过期）。这时候所有的请求都会打到数据库上，数据库的瞬时请求量大、压力骤增，一旦没有抗住瞬时巨大请求量宕机了，那么原本发给这个节点的请求会顺延到下一个节点，这意味着下一个节点将要承受更大的压力，如果它也没有抗住，那么更大的请求压力将施加到下一个节点，就像滚雪球一样，压力越来越大，最终导致所有服务器都失效，这就是缓存雪崩。

# 一致性 hash 算法

一致性哈希算法将 key 映射到 2 ^ 32 次方大小的空间中，将这些数字收尾相连，形成一个环。

## OP1 放置节点到环上

将节点放置到环上：计算节点/机器的哈希值，放置在环上的对应位置（通常使用节点的名称、编号和 IP 地址作为 hash 的参数）

## OP2 将 key 映射到某个节点

计算 key 的 hash 值，放置在环上，顺时针找到的第一个节点，就是应该选择的节点/机器。

## OP3 新增节点

[View on canvas](https://app.eraser.io/workspace/Ez1xesl5oCIADCtL5tLk?elements=sD0yEvzGghQxWvCX7ILI6Q) 

如图新增一个节点，只会影响 key27 -> peer8 之间这部分的节点选择，不需要重新定位所有的节点，这就解决了节点增删导致大量缓存失效的问题。

> 实际上就是通过增加节点的方式，将整个环划分的更加均匀，这样每个节点失效影响的范围就不会像只有几个节点时那么大了。

在实际的使用过程中，节点之间是通过 group 划分的，每个 group 中包含了若干个节点。对应的一致性 hash 的两次为：
1. 给每个节点（集群）计算 Hash，记录他们的 hash 值，这就是它们在环上的位置；
2. 给每个 key 计算 hash，然后沿着顺时针的方向找到环上的第一个节点（集群），就是缓存了该 key 值的节点（集群）。
[View on canvas](https://app.eraser.io/workspace/Ez1xesl5oCIADCtL5tLk?elements=ipn7t3Zkex4PH5j6IMeAig) 

# 数据倾斜问题

如果节点的数量很少，而 hash 环的空间很大，直接进行一致性 hash 的话，大部分情况下节点在环上的位置会很不均匀，有可能都分布在一个很小的范围内。

在这种情况下大量的请求都会打到这个范围最小 hash 处的那个节点，很容易导致缓存雪崩。

除此之外，因为大量的 key 请求都达到某一个节点上，就会导致某个节点缓存了大量的数据，而其他节点几乎没有缓存数据，发生了严重的**数据倾斜**。

解决数据倾斜问题的最好办法就是扩展整个环上的节点数量，因此引入了虚拟节点的概念。

一个实际节点会映射多个虚拟节点，这样 hash 环上的空间分割就会变得均匀。

> 在没有引入虚拟节点的情况下，一旦某个节点宕机，那么原本发给它的请求会顺延到顺时针的下一个节点，在有些情况下可能导致缓存雪崩。而引入虚拟节点后，会使节点在 Hash 环上的顺序随机化，这意味着当一个真实节点失效退出后，他原来所承载的压力将会均匀的分散到其他节点上去。

![image.png](https://eraser.imgix.net/workspaces/Ez1xesl5oCIADCtL5tLk/GtukjIomTTXr5wDxQHR7p5MKXlY2/XKzU1OdVH_IYufP_lP4hN.png?ixlib=js-3.7.0 "image.png")

> 所谓数据倾斜就是环中节点数量比较少又或者是分布比较集中，导致大部分的 key 都打到某一个集群上，也就是我们常说的负载不均衡。为了解决这个问题，最好的方式是让服务器尽可能多，这样才能均匀的划分哈希环。因此我们在原来真实节点数量的基础上，将一个真实节点映射到多个虚拟节点，这些虚拟节点都对应这一个真实节点，这样就相当于给环中增加了几倍的服务器数量，就能让环的划分更加均匀，也就使每个真实节点的请求负载更加均衡。

> 虚拟节点还有一个用途就是：当某个节点因为扛不住访问压力崩溃了，不会将所有的压力都施加到下一个节点，而是均匀分布给其他节点；（一个真实节点宕机后，对应环上的多个虚拟节点将失效，这些请求会顺延给虚拟节点的下一个虚拟节点对应的真实节点；因为虚拟节点在环中的位置是随机的，所以下一个虚拟节点也是随机的，这样就能将请求分给其他节点而不是一个点了），下一个节点不需要抗住两倍的流量。


# Go 语言实现

在 geecache 目录下新建 package consistenthash，用来实现一致性哈希算法

![image.png](https://eraser.imgix.net/workspaces/Ez1xesl5oCIADCtL5tLk/GtukjIomTTXr5wDxQHR7p5MKXlY2/Iu-hP3hRXdhk0L12CvMt8.png?ixlib=js-3.7.0 "image.png")

# 数据结构

## Map

Map 是一致性 hash 算法的主数据结构，包含了四个成员变量

- hash：Hash 函数，默认使用 crc32.ChecksumIEEE 哈希函数
- replicas：虚拟节点是真实节点的倍数
- keys：真实节点对应的所有虚拟节点名称（sorted）
- hashMap：虚拟节点与真实节点间的映射表

```go
type Map struct {
  hash Hash
  replicas int
  keys []int
  hashMap map[int]string
}
```

## Hash 函数

hash 函数是将字节切片转换成一个确定的 uint32 整数打在 hash 环上。

```go
type Hash func(data []byte) uint32
```

## 构造函数

允许我们自定义虚拟节点倍数和所使用的 hash 函数。

```go
func New(replicas int, fn Hash) *Map {
  m := &Map{
    replicas: replicas,
    hash: fn,
    hashMap: make(map[int]string),
  }
  if m.hash ==nil {
    m.hash = crc32.ChecksumIEEE
  }
  return m
}
```

# 添加真实节点 Add

需要提供所有真实节点名称的字符串切片；

```go
func (m *Map) Add(keys ...string) {
  for _, key := range keys {
    for i := 0; i < m.replicas; i++ {
      hash := int(m.hash([]byte(strconv.Itoa(i)+key)))
      m.keys = append(m.keys, hash)
      m.hashMap[hash] = key
    }
  }
  sort.Ints(m.keys)
}
```
1. Add 函数允许传入一个或者多个真实节点的名称
2. 对每个真实节点，创建 m.replicas 个虚拟节点，虚拟节点的名称是：strconv.Itoa(i)+nodename（通过在真实节点名称前添加编号）
3. 使用一致性哈希结构体中定义的哈希函数计算虚拟节点的哈希值，然后追加到 hash 环上，实际上就是添加到存储虚拟节点的切片中；
4. 再将真实节点对应的每个虚拟节点打到环上后，我们还需要记录虚拟节点对应的真实节点，要维护好这个映射关系。
5. 最后一步，对环上的哈希值从小到大排序。（顺时针排序）


# 选择节点 Get

 根据 key 值选择节点；

```go
func (m *Map) Get(key string) string {
  // 0 合法性校验
  if len(m.keys) == 0 {
    return ""
  }
  // 1. get key's hash
  hash := int(m.hash([](key)))
  // 2. clockwise search first node (大于等于该 hash 值的第一个虚拟节点)
  idx := sort.Search(len(m.keys), func(i int) bool {
    return m.keys[i] >= hash
  })
  return m.hashMap[m.keys[idx]%len(m.keys)]
}
```

1. 根据一致性哈希结构体中自定义的哈希函数计算 key 的 hash 值（整数形式）
2. 顺时针找到第一个匹配的虚拟节点下标 idx（这里需要对 hash 虚拟节点长度取余，假设最大虚拟节点的 hash 值为 2^31 ，而 key 计算得到的 hash 值为 2^31 + 1，那么通过调用 sort.Search 返回的 idx 值就是虚拟节点切片的长度，显然越界了，实际上应该达到第一个节点的，所以使用取余处理这种特殊情况）
3. 找到虚拟节点后，再通过虚拟节点和真实节点的映射表找到对应的真实节点。

至此，整个一致性 hash 算法就完成了。



# 测试部分

1. 为了方便，我们自定义 hash 函数，限定 key 的类型为可以直接转换为整型的字符串，然后直接以整型的形式返回它的 hash 值（就是数字本身）。
2. 测试添加三个真实节点，分别是 "2", "4", "6"
3. 每个真实节点都包含了三个虚拟节点
	1. "02" "12" "22" -> "02" 即 “2”
	2. "4", "14" "24"
	3. "6", "16", "26"
4. 我们测试的 key 值分别为 2 11 23 27，根据映射规则
5. 2 应该打到真实节点 2 上
6. 11 应该打到真实节点 2 上（11 找到的虚拟节点是 12）
7. 23 应该打到真实节点 4 上（23 找到的虚拟节点是 24）
8. 27 应该打到真实节点 2 上（因为 27 之后没有虚拟节点了，默认第一个节点）
9. 遍历所有测试用例，调用 m.Get(k) 获取真实节点名称，如果和 expect 值不同则测试失败；
10. 增加一个新的节点 8
	1. "8" "18" "28"
11. 此时 27 应该打到节点 8

```go
package consistenthash

import (
	"strconv"
	"testing"
)

func TestConsistentHash(t *testing.T) {
	hash := NewMap(3, func(key []byte) uint32 {
		i, _ := strconv.Atoi(string(key))

		return uint32(i)
	})

	// 6 16 26
	// 4 14 24
	// 2 12 22
	hash.Add("6", "4", "2")

	testCases := map[string]string{
		"2":  "2",
		"11": "2",
		"23": "4",
		"27": "2",
	}

	for k, v := range testCases {
		if hash.Get(k) != v {
			t.Errorf("Asking for %s, should have yield %s", k, v)
		}
	}

	hash.Add("8")

	testCases["27"] = "8"

	for k, v := range testCases {
		if hash.Get(k) != v {
			t.Errorf("Asking for %s, should have yielded %s", k, v)
		}
	}
}
```

