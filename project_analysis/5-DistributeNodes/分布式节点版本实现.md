# 防止缓存雪崩

# 缓存雪崩、击穿、穿透

缓存雪崩：缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。缓存雪崩通常因为缓存服务器宕机或者缓存的 key 设置了相同的过期时间等引起。

缓存击穿：一个存在的key，在缓存过期的一刻，同时有大量的请求，这些请求都会击穿缓存打到 DB ，造成瞬时DB请求量大、压力骤增。

缓存穿透：查询一个不存在的数据，因为不存在则不会写到缓存中，所以每次都会去请求 DB，如果瞬间流量过大，这些请求会穿透缓存直接打到 DB 上，可能导致服务器宕机。



# SingleFlight 实现

我们在第 5 部分实现了分布式节点，并将相同 key 的请求均打到相同的分布式缓存节点上，我们发起重复 key 的 N 次并发查询，相当于同时向服务节点发起了 N 次请求，如果我们不对数据库访问做任何限制，一旦这个 key 缓存失效或者 key 不存在，这 N 个请求很可能都打到服务器的数据库上，如果这个请求量很大，很容易导致缓存击穿和穿透，甚至导致服务器宕机；

即使对数据库访问做了限制，但是为大量重复的 key 查询都开启一个 HTTP 请求去查询还是太浪费了，因为 http 请求是非常耗费资源的操作，针对 N 次相同的 key 并发查询，向节点发送 N 次请求是没有必要的，我们可以让其中一个去查询，然后将结果告诉并发的其他请求就可以了，这个机制也叫做 singleFlight 机制。

首先我们需要创建一个表示查询状态的结构，它可以阻塞其他协程发起 http 请求，这里我们需要用到 sync.WaitGroup；同时我们用来保存从远端节点查询到的结果；

- 当 val 为 nil 时说明还未从远端查询到缓存值
- 当 val 不为 nil 时，说明之前这个 key 已经查询过了，当前 value 的值就是缓存值，可以直接取走使用；
	除此之外，我们还需要一个错误字段来保存调用过程中的错误信息

- 如果调用发生错误，那么存储的就是错误的信息；
- 如果调用没有发生错误，那么就是 nil

这个表示查询状态的结构将作为查询键的值存储在字典中，这样当相同 key 的请求到达时，检查这个键的是否已经在字典中存在，如果时，说明有正在查询的 goroutine，或者已经查询结束获取缓存值并存入value字段中了；

- 如果 value 字段不为 nil，那么直接取值返回；
- 如果 value 字段为空，那么这个请求可以根据是否愿意阻塞等待进行两种不同的操作
	- 如果愿意阻塞等待查询结果，那么就调用任务编排器的 wait 方法和执行查询的 goroutine 一起阻塞等待调用返回；
	- 如果不愿意阻塞等待，直接返回未查询到，过一会再来查；
这样就可以保证多个相同的并发查询请求只会发起一次查询，大大降低了 http 请求的数量，提高系统的性能。（阻塞等待通过任务编排器来完成！）

```go
type call struct {
  wg sync.WaitGroup
  val interface{}
  err error
}
```

call 代表正在进行中或者已经结束的请求，使用 sync.WaitGroup 锁避免其他 goroutine 进入。

为了保证并发读写 map 的安全性，我们需要将这个字典置于一个结构体中使用互斥锁保护起来。

```go
type Group struct {
  mu sync.Mutex // protect m
  m map[string]*call // 注册 key 的请求
}
```

Group 是 singleFlight 的主数据结构，管理不同 key 的请求（call）；

实现 Do 方法

```go
func (g *Group) Do(key string, fn func() (interface{}, error)) (interface{}, error) {
  // 惰性初始化
  g.mu.Lock()
  if g.m == nil {
    g.m = make(map[string]*call)
  }
  if c, ok := g.m[key]; ok {
    g.mu.Unlock()
    c.wg.Wait() // 和负责去查询的并发 goroutine 一起阻塞等待
    return c.val, c.err
  }
  // 作为第一个负责查询的 goroutine
  c := new(call)
  c.wg.Add(1)
  // 相当于上锁
  g.m[key] = c
  g.mu.Unlock()
  
  c.val, c.err = fn()
  c.wg.Done()
  
  g.mu.Lock()

  // 删除这个 key，这个请求只负责这一段时间并发查询，为了保证尽量取得最新的缓存值，在查询结束后，将 key 从 map 中移除，再去请求更新的缓存值
  delete(g.m, key)
  g.mu.Unlock()
  
  return c.val, c.err
}
```

- Do 方法，接收 2 个参数，第一个参数是 key，第二个参数是一个函数 fn。Do 的作用就是，针对相同的 key，**无论 Do 被调用多少次，函数 fn 都只会被调用一次，等待 fn 调用结束了，返回返回值或错误**；

g.mu 是保护 Group 的成员变量 m 不被并发读写而加上的锁。为了便于理解 Do 函数，我们将 g.mu 暂时去掉，并且把 g.m 延迟初始化的部分去掉，延迟初始化的目的很简单，提高内存使用效率。

```go
func (g *Group) Do(key string, fn func()(interface{}, error)) (interface{}, error) {
  // 如果已经在查询或者查询到了
  if c, ok := g.m[key]; ok {
    c.wg.Wait()
    return c.val, c.err
  }  
  c := new(call)
  c.wg.Add(1)
  g.m[key] = c
  
  c.val, c.err = fn()
  c.wg.Done()
  delete(g.m, key)

  return c.val, c.err
}
```

并发 goroutine 之间不需要消息传递，非常适合 sync.WaitGroup；

- wg.Add(1) 锁加 1
- wg.Wait() 阻塞，直到锁被释放
- wg.Done() 锁减 1


# singleFlight

引入 singleflight.Group

use singleflight.Group to make sure that each key is only fetched once

使用 singleflight.Group 确保每个键仅获取一次

```go
type Group struct {
  name string
  getter Getter
  mainCache cache
  peers PeerPicker
  
  loader *singleflight.Group
}
```


- 修改构造函数 NewGroup
主要是添加一个实例化 singleflight.Group 的逻辑

```go
func NewGroup(name string, cacheBytes int64, getter Getter) *Group {
  //...
  g := &Group {
    //...
    loader: &singleflight.Group{},
  }
  return g
}
```

- 修改加载函数
无论并发调用者的数量如何，每个键在并发请求期间只被获取一次(本地或远程)。

```go
func (g *Group) load(key string) (value ByteView, err error) {
  viewi, err := g.loader.Do(key, func() (interface{}, error) {
    if g.peers != nil { // 存在多个分布式缓存节点
      if peer, ok := g.peers.PickPeer(key); ok { // 根据 key 选择节点
        if value, err := g.getFromPeer(peer, key); err == nil { // 从选中的远端节点获取 key 的缓存值
          return value, nil
        }
        log.Println("[GeeCache] Failed to get from peer", err)
      }
    }
    return g.getLocally(key)
  })
  if err == nil {
    return viewi.(ByteView), nil
  }
  return
}
```

- 修改 geecache.go 中的 Group，添加成员变量 loader，并更新构建函数 NewGroup 。
- 修改 load 函数，将原来的 load 的逻辑，使用 g.loader.Do 包装起来即可，这样确保了并发场景下针对相同的 key，load 过程只会调用一次。


# 测试

执行 run.sh 就可以看到效果了

```bash
./run.sh
```

可以看到，向 API 发起了三次并发请求，但8003 只向 8001 发起了一次请求，就搞定了。

如果并发度不够高，可能仍会看到向 8001 请求三次的场景。

这种情况下三次请求是串行执行的，并没有触发 singleflight 的锁机制工作，可以加大并发数量再测试。即，将 run.sh 中的 curl 命令复制 N 次。

